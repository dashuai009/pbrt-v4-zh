#import "../template.typ": parec, ez_caption

== 10.4 Image Texture
<image-texture>
#parec[
  Image textures store 2D arrays of point-sampled values of a texture function. They use these samples to reconstruct a continuous image function that can be evaluated at an arbitrary $(s , t)$ position.#footnote[
    The term _texture map_ is often used to refer tothis type of texture, although this usage blurs the distinction between themapping that computes texture coordinates and the texture function itself.
  ] These sample values are often called #emph[texels];, since they are similar to pixels in an image but are used in the context of a texture. Image textures are the most widely used type of texture in computer graphics; digital photographs, scanned artwork, images created with image-editing programs, and images generated by renderers are all extremely useful sources of data for this particular texture representation (@fig:image-texture-example).
][
  图像纹理存储了纹理函数的二维点采样值数组。它们使用这些样本来重建一个可以在任意位置 $(s , t)$ 评估的连续图像函数。#footnote[] 这些样本值通常被称为#emph[纹素];，因为它们类似于图像中的像素，但在纹理的上下文中使用。图像纹理是计算机图形学中使用最广泛的纹理类型；数码照片、扫描的艺术作品、使用图像编辑程序创建的图像以及渲染器生成的图像都是这种特定纹理表示的极其有用的数据来源（@fig:image-texture-example）。
]


#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/pha10f14.svg"),
  caption: [
    #ez_caption[
      An Example of Image Textures. Image textures are used
      throughout the #emph[Watercolor] scene to represent spatially
      varying surface appearance properties. (a) Scene rendered with image
      textures. (b) Each image texture has been replaced with its average
      value. Note how much visual richness is lost. #emph[(Scene courtesy
    of Angelo Ferretti.)]
    ][
      图像纹理示例。在#emph[水彩];场景中，图像纹理被广泛用于表示空间变化的表面外观属性。(a)
      使用图像纹理渲染的场景。(b) 每个图像纹理都被其平均值替换。注意视觉丰富度的损失。#emph[(场景由 Angelo Ferretti 提供。)]
    ]
  ],
)<image-texture-example>


#parec[
  As with most of the other types of texture, `pbrt` provides both `Float` and spectral variants. Both implementations inherit from #link("<ImageTextureBase>")[`ImageTextureBase`];, which provides some common functionality.
][
  与大多数其他类型的纹理一样，`pbrt` 提供了 `Float` 和光谱变体。两种实现都继承自 #link("<ImageTextureBase>")[`ImageTextureBase`];，提供了一些通用功能。
]

```cpp
class ImageTextureBase {
  public:
    // <<ImageTextureBase Public Methods>>
    ImageTextureBase(TextureMapping2D mapping, std::string filename,
               MIPMapFilterOptions filterOptions, WrapMode wrapMode, Float scale,
               bool invert, ColorEncoding encoding, Allocator alloc)
           : mapping(mapping), filename(filename), scale(scale), invert(invert) {
              <<Get MIPMap from texture cache if present>>
              TexInfo texInfo(filename, filterOptions, wrapMode, encoding);
              std::unique_lock<std::mutex> lock(textureCacheMutex);
              if (auto iter = textureCache.find(texInfo); iter != textureCache.end()) {
                  mipmap = iter->second;
                  return;
              }
              lock.unlock();
              <<Create MIPMap for filename and add to texture cache>>
              mipmap = MIPMap::CreateFromFile(filename, filterOptions, wrapMode,
                                              encoding, alloc);
              lock.lock();
              textureCache[texInfo] = mipmap;
       }
       static void ClearCache() { textureCache.clear(); }
       void MultiplyScale(Float s) { scale *= s; }
  protected:
    // <<ImageTextureBase Protected Members>>
       TextureMapping2D mapping;
       std::string filename;
       Float scale;
       bool invert;
       MIPMap *mipmap;
  private:
    // <<ImageTextureBase Private Members>>
    static std::mutex textureCacheMutex;
       static std::map<TexInfo, MIPMap *> textureCache;
};
```


#parec[
  In the following, we will present the implementation of `SpectrumImageTexture`;`FloatImageTexture` is analogous and does not add anything new.
][
  接下来，我们将介绍 `SpectrumImageTexture` 的实现；`FloatImageTexture` 类似，并没有添加新的内容。
]

```cpp
class SpectrumImageTexture : public ImageTextureBase {
  public:
    <<SpectrumImageTexture Public Methods>>       SpectrumImageTexture(TextureMapping2D mapping, std::string filename,
               MIPMapFilterOptions filterOptions, WrapMode wrapMode, Float scale,
               bool invert, ColorEncoding encoding, SpectrumType spectrumType,
               Allocator alloc)
           : ImageTextureBase(mapping, filename, filterOptions, wrapMode,
                              scale, invert, encoding, alloc),
             spectrumType(spectrumType) {}
       PBRT_CPU_GPU
       SampledSpectrum Evaluate(TextureEvalContext ctx,
                                SampledWavelengths lambda) const;
       static SpectrumImageTexture *Create(const Transform &renderFromTexture,
                                           const TextureParameterDictionary &parameters,
                                           SpectrumType spectrumType, const FileLoc *loc, Allocator alloc);
       std::string ToString() const;
  private:
    <<SpectrumImageTexture Private Members>>       SpectrumType spectrumType;
};
```


=== Texture Memory Management
<texture-memory-management>
#parec[
  The caller of `SpectrumImageTexture`'s constructor provides a texture mapping function, the filename of an image, various parameters that control the filtering of the image map, how boundary conditions are managed, and how colors are converted to spectral samples. All the necessary initialization is handled by #link("<ImageTextureBase>")[`ImageTextureBase`];.
][
  `SpectrumImageTexture` 构造函数的调用者提供了一个纹理映射函数、图像的文件名、控制图像映射过滤的各种参数、如何管理边界条件以及如何将颜色转换为光谱样本。所有必要的初始化由 #link("<ImageTextureBase>")[`ImageTextureBase`] 处理。
]

```cpp
SpectrumImageTexture(TextureMapping2D mapping, std::string filename,
        MIPMapFilterOptions filterOptions, WrapMode wrapMode, Float scale,
        bool invert, ColorEncoding encoding, SpectrumType spectrumType,
        Allocator alloc)
    : ImageTextureBase(mapping, filename, filterOptions, wrapMode,
                       scale, invert, encoding, alloc),
      spectrumType(spectrumType) {}
```



#parec[
  As was discussed in @from-rgb-to-specturm , RGB colors are transformed into spectra differently depending on whether or not they represent reflectances. The `spectrumType` records what type of RGB a texture represents.
][
  如 @from-rgb-to-specturm 所讨论的，RGB 颜色在转换为光谱时会有所不同，具体取决于它们是否表示反射率。`spectrumType` 记录了纹理所表示的 RGB 类型。
]

```cpp
SpectrumType spectrumType;
```


#parec[
  The contents of the image file are used to create an instance of the #link("<MIPMap>")[`MIPMap`] class that stores the texels in memory and handles the details of reconstruction and filtering to reduce aliasing.
][
  图像文件的内容用于创建 #link("<MIPMap>")[`MIPMap`] 类的实例，该类在内存中存储纹素，并处理重建和过滤的细节以减少混叠。
]

```cpp
ImageTextureBase(TextureMapping2D mapping, std::string filename,
        MIPMapFilterOptions filterOptions, WrapMode wrapMode, Float scale,
        bool invert, ColorEncoding encoding, Allocator alloc)
    : mapping(mapping), filename(filename), scale(scale), invert(invert) {
    <<Get MIPMap from texture cache if present>>       TexInfo texInfo(filename, filterOptions, wrapMode, encoding);
       std::unique_lock<std::mutex> lock(textureCacheMutex);
       if (auto iter = textureCache.find(texInfo); iter != textureCache.end()) {
           mipmap = iter->second;
           return;
       }
       lock.unlock();
    <<Create MIPMap for filename and add to texture cache>>       mipmap = MIPMap::CreateFromFile(filename, filterOptions, wrapMode,
                                       encoding, alloc);
       lock.lock();
       textureCache[texInfo] = mipmap;
}
```

#parec[
  A floating-point scale can be specified with each texture; it is applied to the values returned by the `Evaluate()` method. Further, a `true` value for the `invert` parameter causes the texture value to be subtracted from 1 before it is returned. While the same functionality can be achieved with scale and mix textures, it is easy to also provide that functionality directly in the texture here. Doing so can lead to more efficient texture evaluation on GPUs, as is discussed further in @surface-scattering .
][
  每个纹理可以指定一个浮点比例；它应用于 `Evaluate()` 方法返回的值。此外，`invert` 参数为 `true` 时，会在返回之前从 1 中减去纹理值。虽然可以通过比例和混合纹理实现相同的功能，但在这里直接提供该功能也很容易。这样做可以在 GPU 上实现更高效的纹理评估，如@surface-scattering 进一步讨论的那样。
]

```cpp
TextureMapping2D mapping;
std::string filename;
Float scale;
bool invert;
MIPMap *mipmap;
```

#parec[
  Each MIP map may require a meaningful amount of memory, and a complex scene may have thousands of image textures. Because an on-disk image may be reused for multiple textures in a scene, `pbrt` maintains a table of MIP maps that have been loaded so far so that they are only loaded into memory once even if they are used in more than one image texture.
][
  每个 MIP 映射可能需要大量内存，而一个复杂的场景可能有数千个图像纹理。因为磁盘上的图像可能在场景中被多个纹理重用，所以 `pbrt` 维护了一个已加载 MIP 映射的表，以便即使它们在多个图像纹理中使用，也只加载到内存中一次。
]

#parec[
  `pbrt` loads textures in parallel after the scene description has been parsed; doing so reduces startup time before rendering begins. Therefore, a mutex is used here to ensure that only one thread accesses the texture cache at a time. Note that if the `MIPMap` is not found in the cache, the lock is released before it is read so that other threads can access the cache in the meantime.
][
  `pbrt` 在场景描述解析后并行加载纹理；这样做减少了渲染开始前的启动时间。因此，这里使用互斥锁以确保一次只有一个线程访问纹理缓存。注意，如果在缓存中未找到 `MIPMap`，则在读取之前释放锁，以便其他线程可以同时访问缓存。
]

```cpp
TexInfo texInfo(filename, filterOptions, wrapMode, encoding);
std::unique_lock<std::mutex> lock(textureCacheMutex);
if (auto iter = textureCache.find(texInfo); iter != textureCache.end()) {
    mipmap = iter->second;
    return;
}
lock.unlock();
```

#parec[
  The texture cache itself is managed with a `std::map`.
][
  纹理缓存本身由 `std::map` 管理。
]

```cpp
static std::mutex textureCacheMutex;
static std::map<TexInfo, MIPMap *> textureCache;
```


#parec[
  `TexInfo` is a simple structure that acts as a key for the texture cache `std::map`. It holds all the specifics that must match for a `MIPMap` to be reused in another image texture.
][
  `TexInfo` 是一个简单的结构，作为纹理缓存 `std::map` 的键。它包含了所有必须匹配的细节，以便在另一个图像纹理中重用 `MIPMap`。
]

```cpp
struct TexInfo {
    <<TexInfo Public Methods>>
    TexInfo(const std::string &f, MIPMapFilterOptions filterOptions, WrapMode wm,
               ColorEncoding encoding)
           : filename(f), filterOptions(filterOptions), wrapMode(wm), encoding(encoding) {}
       bool operator<(const TexInfo &t) const {
           return std::tie(filename, filterOptions, encoding, wrapMode) <
                  std::tie(t.filename, t.filterOptions, t.encoding, t.wrapMode);
       }
    std::string ToString() const;
    std::string filename;
    MIPMapFilterOptions filterOptions;
    WrapMode wrapMode;
    ColorEncoding encoding;
};
```


#parec[
  The `TexInfo` constructor, not included here, sets its member variables with provided values. Its only other method is a comparison operator, which is required by `std::map`.
][
  `TexInfo` 构造函数（未包含在此）使用提供的值设置其成员变量。它唯一的其他方法是比较运算符，这是 `std::map` 所需的。
]

```cpp
bool operator<(const TexInfo &t) const {
    return std::tie(filename, filterOptions, encoding, wrapMode) <
           std::tie(t.filename, t.filterOptions, t.encoding, t.wrapMode);
}
```


#parec[
  If the texture has not yet been loaded, a call to `CreateFromFile()` yields a `MIPMap` for it. If the file is not found or there is an error reading it, `pbrt` exits with an error message, so a `nullptr` return value does not need to be handled here.
][
  如果纹理尚未加载，则调用 `CreateFromFile()` 会为其生成一个 `MIPMap`。如果找不到文件或读取时出错，`pbrt` 会以错误消息退出，因此这里不需要处理 `nullptr` 返回值。
]

```cpp
mipmap = MIPMap::CreateFromFile(filename, filterOptions, wrapMode,
                                encoding, alloc);
lock.lock();
textureCache[texInfo] = mipmap;
```



=== Image Texture Evaluation
<image-texture-evaluation>


#parec[
  Before describing the #link("<MIPMap>")[`MIPMap`] implementation, we will discuss the #link("<SpectrumImageTexture>")[SpectrumImageTexture] `Evaluate()` method.
][
  在描述 #link("<MIPMap>")[`MIPMap`] 实现之前，我们会讨论 #link("<SpectrumImageTexture>")[SpectrumImageTexture] 的 `Evaluate()` 方法。
]

```cpp
SampledSpectrum SpectrumImageTexture::Evaluate(
        TextureEvalContext ctx, SampledWavelengths lambda) const {
    <<Apply texture mapping and flip t coordinate for image texture lookup>>       TexCoord2D c = mapping.Map(ctx);
       c.st[1] = 1 - c.st[1];
    <<Lookup filtered RGB value in MIPMap>>       RGB rgb = scale * mipmap->Filter<RGB>(c.st, {c.dsdx, c.dtdx},
                                                   {c.dsdy, c.dtdy});
       rgb = ClampZero(invert ? (RGB(1, 1, 1) - rgb) : rgb);
    <<Return SampledSpectrum for RGB image texture value>>       if (const RGBColorSpace *cs = mipmap->GetRGBColorSpace(); cs) {
           if (spectrumType == SpectrumType::Unbounded)
               return RGBUnboundedSpectrum(*cs, rgb).Sample(lambda);
           else if (spectrumType == SpectrumType::Albedo)
               return RGBAlbedoSpectrum(*cs, Clamp(rgb, 0, 1)).Sample(lambda);
           else
               return RGBIlluminantSpectrum(*cs, rgb).Sample(lambda);
       }
       DCHECK(rgb[0] == rgb[1] && rgb[1] == rgb[2]);
       return SampledSpectrum(rgb[0]);
}
```


#parec[
  It is easy to compute the $(s , t)$ texture coordinates and their derivatives for filtering with the #link("../Textures_and_Materials/Texture_Coordinate_Generation.html#TextureMapping2D")[`TextureMapping2D`];'s `Map()` method. However, the $t$ coordinate must be flipped, because `pbrt`'s #link("../Utilities/Images.html#Image")[`Image`] class (and in turn, #link("<MIPMap>")[`MIPMap`];, which is based on it) defines $(0 , 0)$ to be the upper left corner of the image, while image textures have $(0 , 0)$ at the lower left. (These are the typical conventions for indexing these entities in computer graphics.)
][
  使用 #link("../Textures_and_Materials/Texture_Coordinate_Generation.html#TextureMapping2D")[`TextureMapping2D`] 的 `Map()` 方法，很容易计算出用于过滤的 $(s , t)$ 纹理坐标及其导数。然而，必须翻转 $t$ 坐标，因为 `pbrt` 的 #link("../Utilities/Images.html#Image")[`Image`] 类（以及基于它的 #link("<MIPMap>")[`MIPMap`];）将 $(0 , 0)$ 定义为图像的左上角，而图像纹理则定义为左下角。（这些是计算机图形学中索引这些实体的典型惯例。）
]


```cpp
TexCoord2D c = mapping.Map(ctx);
c.st[1] = 1 - c.st[1];
```

#parec[
  The #link("<MIPMap>")[`MIPMap`];'s `Filter()` method provides the filtered value of the image texture over the specified region; any specified scale or inversion is easily applied to the value it returns. A call to `ClampZero()` here ensures that no negative values are returned after inversion.
][
  #link("<MIPMap>")[`MIPMap`] 的 `Filter()` 方法提供了指定区域内图像纹理的过滤值；任何指定的缩放或反转都可以轻松应用于它返回的值。在此调用 `夹紧为零` 确保反转后不会返回负值。
]


```cpp
RGB rgb = scale * mipmap->Filter<RGB>(c.st, {c.dsdx, c.dtdx},
                                            {c.dsdy, c.dtdy});
rgb = ClampZero(invert ? (RGB(1, 1, 1) - rgb) : rgb);
```

#parec[
  As discussed in @rgb-color, an RGB color space is necessary in order to interpret the meaning of an #link("../Radiometry,_Spectra,_and_Color/Color.html#RGB")[RGB] color value. Normally, the code that reads image file formats from disk returns an `RGBCcolorSpace` with the read image. Most RGB image formats default to sRGB, and some allow specifying an alternative color space. (For example, OpenEXR allows specifying the primaries of an arbitrary RGB color space in the image file's metadata.) A color space and the value of `spectrumType` make it possible to create the appropriate type RGB spectrum, and in turn, its #link("../Radiometry,_Spectra,_and_Color/Representing_Spectral_Distributions.html#Spectrum::Sample")[`Spectrum::Sample()`] can be called to get the #link("../Radiometry,_Spectra,_and_Color/Representing_Spectral_Distributions.html#SampledSpectrum")[`SampledSpectrum`] that will be returned.
][
  如 @rgb-color 所述，解释 #link("../Radiometry,_Spectra,_and_Color/Color.html#RGB")[RGB] 颜色值的意义需要一个 RGB 颜色空间。通常，从磁盘读取图像文件格式的代码会返回一个与读取图像一起的 `RGBColorSpace`。大多数 RGB 图像格式默认使用 sRGB，有些允许指定替代的颜色空间。（例如，OpenEXR 允许在图像文件的元数据中指定任意 RGB 颜色空间的原色。）颜色空间和 `spectrumType` 的值使得可以创建适当类型的 RGB 光谱，进而可以调用其 #link("../Radiometry,_Spectra,_and_Color/Representing_Spectral_Distributions.html#Spectrum::Sample")[`Spectrum::Sample()`] 来获取将返回的 #link("../Radiometry,_Spectra,_and_Color/Representing_Spectral_Distributions.html#SampledSpectrum")[`SampledSpectrum`];。
]

#parec[
  If the #link("<MIPMap>")[`MIPMap`] has no associated color space, the image is assumed to have the same value in all channels and a constant value is returned for all the spectrum samples. This assumption is verified by a #link("../Utilities/User_Interaction.html#DCHECK")[`DCHECK()`] call in non-optimized builds.
][
  如果 #link("<MIPMap>")[`MIPMap`] 没有关联的颜色空间，则假定图像在所有通道中具有相同的值，并假定所有光谱样本返回一个常数值。在非优化构建中，这一假设通过 #link("../Utilities/User_Interaction.html#DCHECK")[`DCHECK()`] 调用进行验证。
]

```cpp
if (const RGBColorSpace *cs = mipmap->GetRGBColorSpace(); cs) {
    if (spectrumType == SpectrumType::Unbounded)
        return RGBUnboundedSpectrum(*cs, rgb).Sample(lambda);
    else if (spectrumType == SpectrumType::Albedo)
        return RGBAlbedoSpectrum(*cs, Clamp(rgb, 0, 1)).Sample(lambda);
    else
        return RGBIlluminantSpectrum(*cs, rgb).Sample(lambda);
}
DCHECK(rgb[0] == rgb[1] && rgb[1] == rgb[2]);
return SampledSpectrum(rgb[0]);
```


=== MIP Maps
<mip-maps>
#parec[
  As always, if the image texture function has higher frequency detail than can be represented by the texture sampling rate, aliasing will be present in the final image. Any frequencies higher than the Nyquist limit must be removed by prefiltering before the function is evaluated. @fig:tex-filter-large-area shows the basic problem we face: an image texture has texels that are samples of some image function at a fixed frequency. The filter region for the lookup is given by its $(s , t)$ center point and offsets to the estimated texture coordinate locations for the adjacent image samples. Because these offsets are estimates of the texture sampling rate, we must remove any frequencies higher than twice the distance to the adjacent samples in order to satisfy the Nyquist criterion.
][
  一如既往，如果图像纹理函数的细节频率高于纹理采样率所能表示的频率，最终图像中将出现混叠。任何高于奈奎斯特极限的频率必须在函数评估之前通过预滤波去除。@fig:tex-filter-large-area 展示了我们面临的基本问题：图像纹理具有纹素，它们是以固定频率对某个图像函数的采样。查找的滤波区域由其 $(s , t)$ 中心点和相邻图像样本的估计纹理坐标位置的偏移量给出。因为这些偏移量是纹理采样率的估计值，我们必须去除任何高于相邻样本两倍距离的频率，以满足奈奎斯特准则。
]

#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/pha10f15.svg"),
  caption: [
    #ez_caption[
      Given a point at which to perform an image map lookup (denoted by the solid point in the center) and estimates of the texture-space sampling rate (denoted by adjacent solid points), it may be necessary to filter the contributions of a large number of texels in the image map (denoted by open points).
    ][
      给定一个执行图像映射查找的点（由中心的实心点表示）和纹理空间采样率的估计值（由相邻的实心点表示），可能需要对图像映射中的大量纹素的贡献进行滤波（由空心点表示）。
    ]
  ],
)<tex-filter-large-area>


#parec[
  The texture sampling and reconstruction process has a few key differences from the image sampling process discussed in @sampling-and-reconstruction. These differences make it possible to address the antialiasing problem with more effective and less computationally expensive techniques. For example, here it is inexpensive to get the value of a sample—only an array lookup is necessary (as opposed to having to trace a number of rays to compute radiance). Further, because the texture image function is fully defined by the set of samples and there is no mystery about what its highest frequency could be, there is no uncertainty related to the function's behavior between samples. These differences make it possible to remove detail from the texture before sampling, thus eliminating aliasing.
][
  纹理采样和重建过程与 @sampling-and-reconstruction 讨论的图像采样过程有一些关键区别。这些区别使得可以用更有效且计算成本更低的技术来解决抗混叠问题。例如，在这里，获取样本值是简单且低成本的——只需进行数组查找（而不是必须跟踪多个光线以计算辐射亮度）。此外，由于纹理图像函数完全由样本集定义，并且其最高频率是什么没有疑问，因此在样本之间的函数行为没有不确定性。这些区别使得可以在采样之前从纹理中去除细节，从而消除混叠。
]

#parec[
  However, the texture sampling rate will typically change from pixel to pixel. The sampling rate is determined by scene geometry and its orientation, the texture coordinate mapping function, and the camera projection and image sampling rate. Because the texture sampling rate is not fixed, texture filtering algorithms need to be able to filter over arbitrary regions of texture samples efficiently.
][
  然而，纹理采样率通常会从像素到像素变化。采样率由场景几何及其方向、纹理坐标映射函数以及相机投影和图像采样率决定。由于纹理采样率不是固定的，纹理滤波算法需要能够有效地在任意区域的纹理样本上进行滤波。
]

#parec[
  The #link("<MIPMap>")[`MIPMap`] class implements a number of methods for texture filtering with spatially varying filter widths. It can be found in the files #link("https://github.com/mmp/pbrt-v4/tree/master/src/pbrt/util/mipmap.h")[`util/mipmap.h`] and #link("https://github.com/mmp/pbrt-v4/tree/master/src/pbrt/util/mipmap.cpp")[`util/mipmap.cpp`];. The filtering algorithms it offers range from simple point sampling to bilinear interpolation and trilinear interpolation, which is fast and easy to implement and was widely used for texture filtering in early graphics hardware, to elliptically weighted averaging, which is more complex but returns extremely high-quality results. Figure~#link("<fig:texfilt-ewa-trilerp>")[10.16] compares the result of texture filtering using trilinear interpolation and the EWA algorithm.
][
  #link("<MIPMap>")[`MIPMap`];类实现了用于具有空间变化滤波宽度的纹理滤波的多种方法。它可以在文件#link("https://github.com/mmp/pbrt-v4/tree/master/src/pbrt/util/mipmap.h")[`util/mipmap.h`];和#link("https://github.com/mmp/pbrt-v4/tree/master/src/pbrt/util/mipmap.cpp")[`util/mipmap.cpp`];中找到。它提供的滤波算法从简单的点采样到双线性插值和三线性插值，这种方法快速且易于实现，曾广泛用于早期图形硬件的纹理滤波，到椭圆加权平均，这种方法更复杂但能返回极高质量的结果。图#link("<fig:texfilt-ewa-trilerp>")[10.16];比较了使用三线性插值和EWA算法进行纹理滤波的结果。
]

#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/sphere-ewa-vs-trilerp.png"),
  caption: [
    #ez_caption[
      #strong[Figure 10.16:] Filtering the image map properly substantially
      improves the image. Trilinear interpolation is used for the sphere on
      the left and the EWA algorithm is used for the sphere on the right. Both
      of these approaches give a much better result than the unfiltered image
      map on the sphere on the left in
      Figure~#link("../Textures_and_Materials.html#fig:texture-aliasing-example")[10.1];.
      Trilinear interpolation is not as effective as EWA at handling strongly
      anisotropic filter footprints, which is why the lines on the left sphere
      are blurrier. In regions with highly anisotropic filter footprints such
      as the pole of the sphere and toward the edges, EWA resolves much more
      detail.
    ][
      正确滤波图像映射显著改善了图像。左侧球体使用三线性插值，右侧球体使用EWA算法。这两种方法都比图#link("../Textures_and_Materials.html#fig:texture-aliasing-example")[10.1];中左侧球体的未滤波图像映射效果更好。三线性插值在处理强各向异性滤波足迹时不如EWA有效，这就是为什么左侧球体上的线条更模糊。在具有高度各向异性滤波足迹的区域，如球体的极点和边缘，EWA能解析出更多细节。
    ]
  ],
)<texfilt-ewa-trilerp>


#parec[
  If an RGB image is provided to the `MIPMap` constructor, its channels should be stored in R, G, B order in memory; for efficiency, the following code assumes that this is the case. All the code that currently uses `MIPMaps` in `pbrt` ensures that this is so.
][
  如果将RGB图像提供给`MIPMap`构造函数，其通道应按R、G、B顺序存储在内存中；为了效率，以下代码假设情况如此。当前在`pbrt`中使用`MIPMaps`的所有代码都确保了这一点。
]

```cpp
class MIPMap {
  public:
    <<MIPMap Public Methods>>
    MIPMap(Image image, const RGBColorSpace *colorSpace, WrapMode wrapMode,
              Allocator alloc, const MIPMapFilterOptions &options);
       static MIPMap *CreateFromFile(const std::string &filename,
                                                     const MIPMapFilterOptions &options,
                                                     WrapMode wrapMode,
                                                     ColorEncoding encoding,
                                                     Allocator alloc);
       template <typename T>
       T Filter(Point2f st, Vector2f dstdx, Vector2f dstdy) const;
       std::string ToString() const;
       Point2i LevelResolution(int level) const {
           return pyramid[level].Resolution();
       }
       int Levels() const { return int(pyramid.size()); }
       const RGBColorSpace *GetRGBColorSpace() const { return colorSpace; }
       const Image &GetLevel(int level) const { return pyramid[level]; }
  private:
    <<MIPMap Private Methods>>       template <typename T>
       T Texel(int level, Point2i st) const;
       template <typename T>
       T Bilerp(int level, Point2f st) const;
       template <typename T>
       T EWA(int level, Point2f st, Vector2f dst0, Vector2f dst1) const;
    <<MIPMap Private Members>>       pstd::vector<Image> pyramid;
       const RGBColorSpace *colorSpace;
       WrapMode wrapMode;
       MIPMapFilterOptions options;
};
```


#parec[
  To limit the potential number of texels that need to be accessed, these filtering methods use an #emph[image pyramid] of increasingly lower resolution prefiltered versions of the original image to accelerate their operation. #footnote[The name “MIP map” comes from the Latin _multum
in parvo_ , which means “much in little,” a nod to the image pyramid.] The original image texels are at the bottom level of the pyramid, and the image at each level is half the resolution of the previous level, up to the top level, which has a single texel representing the average of all the texels in the original image. This collection of images needs at most $1 / 3$ more memory than storing the most detailed level alone and can be used to quickly find filtered values over large regions of the original image. The basic idea behind the pyramid is that if a large area of texels needs to be filtered, a reasonable approximation is to use a higher level of the pyramid and do the filtering over the same area there, accessing many fewer texels.
][
  为了限制需要访问的纹素数量，这些滤波方法使用了一个#emph[图像金字塔];，该金字塔是原始图像的逐渐降低分辨率的预滤波版本，以加速其操作。#footnote[] 原始图像纹素位于金字塔的底层，每一层的图像分辨率是上一层的一半，直到顶层，顶层只有一个纹素代表原始图像中所有纹素的平均值。这组图像最多只需要多花费 $1 / 3$ 的内存，相比仅存储最详细的层，并且可以用于快速找到原始图像大区域的滤波值。金字塔的基本思想是，如果需要滤波大面积的纹素，可以使用金字塔的更高层，并在同一区域进行滤波，访问的纹素数量大大减少。
]

#parec[
  The `MIPMap`'s image pyramid is represented by a vector of #link("../Utilities/Images.html#Image")[Image];s. See Section~#link("../Utilities/Images.html#sec:image-class")[B.5] for the implementation of #link("../Utilities/Images.html#Image")[Image] and Section~#link("../Utilities/Images.html#sec:image-pyramids")[B.5.5] for its `GeneratePyramid()` method, which generates image pyramids.
][
  `MIPMap`的图像金字塔由一个#link("../Utilities/Images.html#Image")[Image];的向量表示。参见第#link("../Utilities/Images.html#sec:image-class")[B.5];节了解#link("../Utilities/Images.html#Image")[Image];的实现，以及第#link("../Utilities/Images.html#sec:image-pyramids")[B.5.5];节了解其`GeneratePyramid()`方法，该方法生成图像金字塔。
]

```
pstd::vector<Image> pyramid;
const RGBColorSpace *colorSpace;
WrapMode wrapMode;
MIPMapFilterOptions options;
```

#parec[
  The choice of filtering algorithm and a parameter used by the `EWA` method are represented by `MIPMapFilterOptions`.
][
  滤波算法的选择和`EWA`方法使用的参数由`MIPMapFilterOptions`表示。
]

```
struct MIPMapFilterOptions {
    FilterFunction filter = FilterFunction::EWA;
    Float maxAnisotropy = 8.f;
};
```

```
enum class FilterFunction { Point, Bilinear, Trilinear, EWA };
```


#parec[
  A few simple utility methods return information about the image pyramid and the `MIPMap`'s color space.
][
  一些简单的实用方法返回有关图像金字塔和`MIPMap`的颜色空间的信息。
]

```
Point2i LevelResolution(int level) const {
    return pyramid[level].Resolution();
}
int Levels() const { return int(pyramid.size()); }
const RGBColorSpace *GetRGBColorSpace() const { return colorSpace; }
const Image &GetLevel(int level) const { return pyramid[level]; }
```


#parec[
  Given the image pyramid, we will define some utility #link("<MIPMap>")[`MIPMap`] methods that retrieve the texel value at a specified pyramid level and discrete integer pixel coordinates. For the `RGB` variant, there is an implicit assumption that the image channels are laid out in R, G, B (and maybe A) order.
][
  给定图像金字塔，我们将定义一些实用的#link("<MIPMap>")[`MIPMap`];方法，这些方法在指定的金字塔级别和离散整数像素坐标处检索纹素值。对于`RGB`变体，隐含假设图像通道按R、G、B（可能还有A）顺序排列。
]

```
template <>
RGB MIPMap::Texel(int level, Point2i st) const {
    if (int nc = pyramid[level].NChannels(); nc == 3 || nc == 4)
        return RGB(pyramid[level].GetChannel(st, 0, wrapMode),
                   pyramid[level].GetChannel(st, 1, wrapMode),
                   pyramid[level].GetChannel(st, 2, wrapMode));
    else {
        Float v = pyramid[level].GetChannel(st, 0, wrapMode);
        return RGB(v, v, v);
    }
}
```



#parec[
  The `Float` specialization of `Texel()`, not included here, is analogous.
][
  `Texel()`的`Float`特化版本未包含在此，但类似。
]


=== Image Map Filtering
<image-map-filtering>


#parec[
  The `MIPMap` `Filter()` method returns a filtered image function value at the provided $(s , t)$ coordinates. It takes two derivatives that give the change in $(s , t)$ with respect to image pixel samples.
][
  `MIPMap` 的 `过滤()` 方法返回在给定 $(s , t)$ 坐标处的经过过滤的图像函数值。它接受两个导数，这两个导数提供了 $(s , t)$ 相对于图像像素样本的变化。
]

```cpp
<<MIPMap Method Definitions>>+=
template <typename T>
T MIPMap::Filter(Point2f st, Vector2f dst0, Vector2f dst1) const {
    if (options.filter != FilterFunction::EWA) {
        <<Handle non-EWA MIP Map filter>>
    }
    <<Compute EWA ellipse axes>>
    <<Clamp ellipse vector ratio if too large>>
    <<Choose level of detail for EWA lookup and perform EWA filtering>>
}
```


#parec[
  The `EWA` filtering technique to be described shortly uses both derivatives of $(s , t)$ to compute an #emph[anisotropic filter];—one that filters by different amounts in the different dimensions. The other three use an #emph[isotropic filter] that filters both equally. The isotropic filters are more computationally efficient than the anisotropic filter, though they do not give results that are as good. For them, only a single value is needed to specify the width of the filter. The width here is conservatively chosen to avoid aliasing in both the $s$ and $t$ directions, though this choice means that textures viewed at an oblique angle will appear blurry, since the required sampling rate in one direction will be very different from the sampling rate along the other in this case.
][
  即将描述的 `EWA` 过滤技术使用 $(s , t)$ 的两个导数来计算一个 #emph[各向异性过滤器];，这种过滤器在不同维度上以不同的量进行过滤。其他三种使用的是 #emph[各向同性过滤器];，它们在两个维度上进行相等的过滤。各向同性过滤器在计算上比各向异性过滤器更高效，尽管它们的结果不如后者好。对于它们，只需要一个值来指定过滤器的宽度。这里的宽度是保守选择的，以避免在 $s$ 和 $t$ 方向上产生混叠，尽管这种选择意味着在斜角观察纹理时会显得模糊，因为在这种情况下，一个方向所需的采样率与另一个方向的采样率会非常不同。
]

```cpp
<<Handle non-EWA MIP Map filter>>=
Float width = 2 * std::max({std::abs(dst0[0]), std::abs(dst0[1]),
                            std::abs(dst1[0]), std::abs(dst1[1])});
<<Compute MIP Map level for width and handle very wide filter>>
if (options.filter == FilterFunction::Point) {
    <<Return point-sampled value at selected MIP level>>
} else if (options.filter == FilterFunction::Bilinear) {
    <<Return bilinear-filtered value at selected MIP level>>
} else {
    <<Return trilinear-filtered value at selected MIP level>>
}
```



#parec[
  Because filtering over many texels for wide filter widths would be inefficient, this method chooses a MIP map level from the pyramid such that the filter region at that level would cover four texels at that level. @fig:mipmap-trilerp illustrates this idea.
][
  因为对于宽过滤器宽度在许多纹素上进行过滤效率不高，该方法从金字塔中选择一个 MIP 映射级别，使得该级别的过滤区域覆盖该级别的四个纹素。@fig:mipmap-trilerp 说明了这个想法。
]

#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/pha10f17.svg"),
  caption: [
    #ez_caption[
      Choosing a MIP Map Level for the Triangle Filter. The
      `MIPMap` chooses a level such that the filter covers four texels.
    ][
      为三角形过滤器选择 MIP 映射级别。`MIP 映射`
      选择一个级别，使得过滤器覆盖四个纹素。
    ]
  ],
)<mipmap-trilerp>


#parec[
  Since the resolutions of the levels of the pyramid are all powers of two, the resolution of level $l$ is $2^("nlevels" - 1 - l)$. Therefore, to find the level with a texel spacing width $w$ requires solving
][
  由于金字塔各级的分辨率都是二的幂，级别 $l$ 的分辨率是 $2^("nlevels" - 1 - l)$。因此，要找到纹素间距宽度为 $w$ 的级别，需要解决以下问题：
]

$ 1 / w = 2^("n Levels" - 1 - l) $


#parec[
  for $l$. In general, this will be a floating-point value between two MIP map levels. Values of $l$ greater than the number of pyramid levels correspond to a filter width wider than the image, in which case the single pixel at the top level is returned.
][
  对于 $l$。通常，这将是两个 MIP 映射级别之间的浮点值。当 $l$ 值大于金字塔级别的数量时，表示滤镜宽度超过图像宽度，此时将返回顶层的单个像素。
]

```cpp
int nLevels = Levels();
Float level = nLevels - 1 + Log2(std::max<Float>(width, 1e-8));
if (level >= Levels() - 1)
    return Texel<T>(Levels() - 1, Point2i(0, 0));
int iLevel = std::max(0, int(pstd::floor(level)));
```
#parec[
  For a point-sampled texture lookup, it is only necessary to convert the continuous texture coordinates over $[0,1]$ to discrete coordinates over the image resolution and to retrieve the appropriate texel value via the MIPMap's Texel() method.
][
  对于点采样纹理查找，只需将连续的纹理坐标从 $[0 , 1]$ 转换为图像分辨率上的离散坐标，并通过 `MIPMap` 的 `Texel()` 方法检索适当的纹素值。
]

```cpp
Point2i resolution = LevelResolution(iLevel);
Point2i sti(pstd::round(st[0] * resolution[0] - 0.5f),
            pstd::round(st[1] * resolution[1] - 0.5f));
return Texel<T>(iLevel, sti);
```


#parec[
  Bilinear filtering, which is equivalent to filtering using a triangle filter, is easily implemented via a call to Bilerp().
][
  双线性过滤，相当于使用三角形滤镜进行过滤，可以通过调用 `Bilerp()` 轻松实现。
]
```cpp
return Bilerp<T>(iLevel, st);
```

#parec[
  Bilinear interpolation is provided in a separate method so that it can also be used for trilinear filtering.
][
  双线性插值在一个单独的方法中提供，以便它也可以用于三线性过滤。
]
```cpp
template <>
RGB MIPMap::Bilerp(int level, Point2f st) const {
    if (int nc = pyramid[level].NChannels(); nc == 3 || nc == 4)
        return RGB(pyramid[level].BilerpChannel(st, 0, wrapMode),
                   pyramid[level].BilerpChannel(st, 1, wrapMode),
                   pyramid[level].BilerpChannel(st, 2, wrapMode));
    else {
        Float v = pyramid[level].BilerpChannel(st, 0, wrapMode);
        return RGB(v, v, v);
    }
}
```

#parec[
  As shown by @fig:mipmap-trilerp, applying a triangle filter to the four texels around the sample point will either filter over too small a region or too large a region (except for very carefully selected filter widths). Therefore, the Trilinear filtering option applies the triangle filter at both of these levels and blends between them according to how close level is to each of them. This helps hide the transitions from one MIP map level to the next at nearby pixels in the final image. While applying a triangle filter to four texels at two levels in this manner does not generally give exactly the same result as applying a triangle filter to the original pixels, the difference is not too bad in practice, and the efficiency of this approach is worth this penalty. In any case, the following elliptically weighted average filtering approach should be used when texture quality is important.
][
  如@fig:mipmap-trilerp 所示，将三角形滤镜应用于样本点周围的四个纹素将导致过滤区域过小或过大（除非非常仔细地选择滤镜宽度）。因此，`Trilinear` 过滤选项在这两个级别上应用三角形滤镜，并根据 `level` 与每个级别的接近程度在它们之间进行混合。 这有助于隐藏最终图像中相邻像素之间从一个 MIP 映射级别到下一个级别的过渡。虽然以这种方式将三角形滤镜应用于两个级别的四个纹素通常不会产生与将三角形滤镜应用于原始像素完全相同的结果，但在实践中差异并不大，并且这种方法的效率值得这种代价。无论如何，当纹理质量很重要时，应使用以下椭圆加权平均过滤方法。
]

```cpp
if (iLevel == 0)
    return Bilerp<T>(0, st);
else
    return Lerp(level - iLevel, Bilerp<T>(iLevel, st),
                Bilerp<T>(iLevel + 1, st));
```
#parec[
  The elliptically weighted average (EWA) algorithm fits an ellipse to the two differential vectors in texture space and then filters the texture with a Gaussian filter function (@fig:ewa-ellipse-axes). It is widely regarded as one of the best texture filtering algorithms in graphics and has been carefully derived from the basic principles of sampling theory. Unlike the triangle filter, it can filter over arbitrarily oriented regions of the texture, with different filter extents in different directions. The quality of its results is improved by it being an anisotropic filter, since it can adapt to different sampling rates along the two image axes.
][
  椭圆加权平均（EWA）算法通过将椭圆拟合到纹理空间中的两个微分向量，并使用高斯滤镜函数对纹理进行过滤（如@fig:ewa-ellipse-axes 所示）。它被广泛认为是图形中最好的纹理过滤算法之一，并且已经从采样理论的基本原理中仔细推导出来。与三角形滤镜不同，它可以在纹理的任意方向区域上进行过滤，并且在不同方向上具有不同的滤镜范围。由于它是各向异性滤镜，它可以适应沿两个图像轴的不同采样率，从而提高了其结果的质量。
]
#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/pha10f18.svg"),
  caption: [
    #ez_caption[
      The EWA filter applies a Gaussian filter to the texels in an elliptical area around the evaluation point. The extent of the ellipse is such that its edge passes through the positions of the adjacent texture samples as estimated by the texture coordinate partial derivatives.
    ][
      EWA 滤镜将高斯滤镜应用于评估点周围椭圆区域内的纹素。椭圆的范围使得其边缘通过由纹理坐标偏导数估计的相邻纹理样本的位置。
    ]
  ],
)<ewa-ellipse-axes>


#parec[
  We will not show the full derivation of this filter here, although we do note that it is distinguished by being a _unified resampling filter_: it simultaneously computes the result of a Gaussian filtered texture function convolved with a Gaussian reconstruction filter in image space. This is in contrast to many other texture filtering methods that ignore the effect of the image-space filter or equivalently assume that it is a box. Even if a Gaussian is not being used for filtering the samples for the image being rendered, taking some account of the spatial variation of the image filter improves the results, assuming that the filter being used is somewhat similar in shape to the Gaussian, as the Mitchell and windowed sinc filters are.
][
  我们不会在这里展示这种滤镜的完整推导，尽管我们注意到它的特点是一个_统一的重采样滤镜_：它同时计算与图像空间中的高斯重建滤镜卷积的高斯过滤纹理函数的结果。 这与许多其他忽略图像空间滤镜效果或等效地假设它是一个盒子的纹理过滤方法形成对比。即使没有使用高斯来过滤正在渲染的图像的样本，考虑到图像滤镜的空间变化也会改善结果，假设所使用的滤镜在形状上与高斯有些相似，如 Mitchell 和窗口化 sinc 滤镜。
]

#parec[
  The screen-space partial derivatives of the texture coordinates define the ellipse. The lookup method starts out by determining which of the two axes is the longer of the two, swapping them if needed so that `dst0` is the longer vector. The length of the shorter vector will be used to select a MIP map level.
][
  椭圆是由纹理坐标的屏幕空间偏导数定义的。查找方法首先确定两个轴中哪个更长，如果需要则交换它们，以便 `dst0` 是更长的向量。较短向量的长度将用于选择 MIP 映射级别。
]

```cpp
if (LengthSquared(dst0) < LengthSquared(dst1))
    pstd::swap(dst0, dst1);
Float longerVecLength = Length(dst0), shorterVecLength = Length(dst1);
```
#parec[
  Next the ratio of the length of the longer vector to the length of the shorter one is considered. A large ratio indicates a very long and skinny ellipse. Because this method filters texels from a MIP map level chosen based on the length of the shorter differential vector, a large ratio means that a large number of texels need to be filtered. To avoid this expense (and to ensure that any EWA lookup takes a bounded amount of time), the length of the shorter vector may be increased to limit this ratio. The result may be an increase in blurring, although this effect usually is not noticeable in practice.
][
  接下来考虑较长向量长度与较短向量长度的比率。较大的比率表示一个非常长且瘦的椭圆。由于此方法从基于较短微分向量长度选择的 MIP 映射级别过滤纹素，因此较大的比率意味着需要过滤大量纹素。为了避免这种开销（并确保任何 EWA 查找都需要有限的时间），可以增加较短向量的长度以限制此比率。 结果可能会导致模糊增加，尽管这种效果通常在实践中不明显。
]

```cpp
if (shorterVecLength * options.maxAnisotropy < longerVecLength &&
    shorterVecLength > 0) {
    Float scale = longerVecLength /
        (shorterVecLength * options.maxAnisotropy);
    dst1 *= scale;
    shorterVecLength *= scale;
}
if (shorterVecLength == 0)
    return Bilerp<T>(0, st);
```

#parec[
  Like the triangle filter, the EWA filter uses the image pyramid to reduce the number of texels to be filtered for a particular texture lookup, choosing a MIP map level based on the length of the shorter vector. Given the limited ratio from the clamping above, the total number of texels used is thus bounded. Given the length of the shorter vector, the computation to find the appropriate pyramid level is the same as was used for the triangle filter. Similarly, the implementation here blends between the filtered results at the two levels around the computed level of detail, again to reduce artifacts from transitions from one level to another.
][
  与三角形滤镜一样，EWA 滤镜使用图像金字塔减少特定纹理查找的纹素数量，基于较短向量的长度选择 MIP 映射级别。由于上述限制的比率，使用的纹素总数因此是有限的。给定较短向量的长度，找到适当金字塔级别的计算与用于三角形滤镜的计算相同。 同样，这里的实现在计算的细节级别周围的两个级别之间混合过滤结果，再次减少从一个级别到另一个级别的过渡伪影。
]

```cpp
Float lod = std::max<Float>(0, Levels() - 1 + Log2(shorterVecLength));
int ilod = pstd::floor(lod);
return Lerp(lod - ilod, EWA<T>(ilod, st, dst0, dst1),
            EWA<T>(ilod + 1, st, dst0, dst1));
```

#parec[
  The `MIPMap::EWA()` method actually applies the filter at a particular level.
][
  `MIPMap::EWA()` 方法实际上在特定级别应用滤镜。
]

```cpp
<<MIPMap Method Definitions>>+=
template <typename T>
T MIPMap::EWA(int level, Point2f st, Vector2f dst0, Vector2f dst1) const {
    if (level >= Levels())
        return Texel<T>(Levels() - 1, {0, 0});
    <<Convert EWA coordinates to appropriate scale for level>>
    <<Find ellipse coefficients that bound EWA filter region>>
    <<Compute the ellipse’s  bounding box in texture space>>
    <<Scan over ellipse bound and evaluate quadratic equation to filter image>>
}
```

#parec[
  This method first converts from texture coordinates in $[0 , 1]$ to coordinates and differentials in terms of the resolution of the chosen MIP map level. It also subtracts $0.5$ from the continuous position coordinate to align the sample point with the discrete texel coordinates, as was done in MIPMap::Bilerp().
][
  该方法首先将纹理坐标从 $[0 , 1]$ 转换为所选 MIP 映射级别的分辨率坐标和微分。它还从连续位置坐标中减去 $0.5$ 以将样本点与离散纹素坐标对齐，就像在 `MIPMap::Bilerp()` 中所做的那样。
]

```cpp
Point2i levelRes = LevelResolution(level);
st[0] = st[0] * levelRes[0] - 0.5f;
st[1] = st[1] * levelRes[1] - 0.5f;
dst0[0] *= levelRes[0];
dst0[1] *= levelRes[1];
dst1[0] *= levelRes[0];
dst1[1] *= levelRes[1];
```
#parec[
  It next computes the coefficients of the implicit equation for the ellipse centered at the origin that is defined by the vectors `(ds0,dt0)` and `(ds1,dt1)`. Placing the ellipse at $(s , t)$ the origin rather than at simplifies the implicit equation and the computation of its coefficients and can be easily corrected for when the equation is evaluated later. The general form of the implicit equation for all points $(s , t)$ inside such an ellipse is
][
  接下来，它计算由向量 `(ds0,dt0)` 和 `(ds1,dt1)` 定义的椭圆的隐式方程的系数，该椭圆以原点为中心。将椭圆放置在原点而不是在 $(s , t)$ 处简化了隐式方程及其系数的计算，并且可以在稍后评估方程时轻松纠正。所有点 $(s , t)$ 在此类椭圆内的隐式方程的一般形式为
]


$ e (s , t) = A s^2 + B s t + C t^2 < F , $
#parec[
  although it is more computationally efficient to divide through by $F$ and express this as
][

]

$ e (s , t) = A / F s^2 + B / F s t + C / F t^2 = A prime s^2 + B prime s t + C prime t^2 < 1 . $

#parec[
  We will not derive the equations that give the values of the coefficients, although the interested reader can easily verify their correctness. #footnote[Heckbert's thesis has the original derivation (Heckbert
  1989b, p.~80): A and C have an extra term of 1 added to them so the
  ellipse is a minimum of one texel separation wide. This ensures that the
  ellipse will not fall between the texels when magnifying at the most
  detailed level.]
][
  我们不会推导出给出系数值的方程，尽管感兴趣的读者可以轻松验证其正确性。#footnote[Heckbert
  的论文中有原始推导 (Heckbert 1989b, p.~80)：A 和 C 具有额外的 1
  项，因此椭圆的最小宽度为一个 texel
  间隔。这确保了在放大到最详细级别时，椭圆不会落在 texel 之间。]
]

```cpp
<<Find ellipse coefficients that bound EWA filter region>>=
Float A = Sqr(dst0[1]) + Sqr(dst1[1]) + 1;
Float B = -2 * (dst0[0] * dst0[1] + dst1[0] * dst1[1]);
Float C = Sqr(dst0[0]) + Sqr(dst1[0]) + 1;
Float invF = 1 / (A * C - Sqr(B) * 0.25f);
A *= invF;
B *= invF;
C *= invF;
```

#parec[
  The next step is to find the axis-aligned bounding box in discrete integer texel coordinates of the texels that are potentially inside the ellipse. The EWA algorithm loops over all of these candidate texels, filtering the contributions of those that are in fact inside the ellipse. The bounding box is found by determining the minimum and maximum values that the ellipse takes in the $s$ and $t$ directions. These extrema can be calculated by finding the partial derivatives $frac(partial e, partial s)$ and $frac(partial e, partial t)$, finding their solutions for $s = 0$ and $t = 0$, and adding the offset to the ellipse center. For brevity, we will not include the derivation for these expressions here.
][
  下一步是找到可能在椭圆内的 texel 的离散整数 texel 坐标中的轴对齐的边界框。EWA 算法遍历所有这些候选 texel，过滤出实际在椭圆内的 texel 的贡献。 通过确定椭圆在 $s$ 和 $t$ 方向上的最小值和最大值来找到边界框。这些极值可以通过找到偏导数 $frac(partial e, partial s)$ 和 $frac(partial e, partial t)$，找到 $s = 0$ 和 $t = 0$ 的解，并将偏移量添加到椭圆中心来计算。为简洁起见，我们在此不包括这些表达式的推导。
]

```cpp
Float det = -B^2 + 4 * A * C;
Float invDet = 1 / det;
Float uSqrt = SafeSqrt(det * C), vSqrt = SafeSqrt(A * det);
int s0 = pstd::ceil(st[0] - 2 * invDet * uSqrt);
int s1 = pstd::floor(st[0] + 2 * invDet * uSqrt);
int t0 = pstd::ceil(st[1] - 2 * invDet * vSqrt);
int t1 = pstd::floor(st[1] + 2 * invDet * vSqrt);
```

#figure(
  image("../pbr-book-website/4ed/Textures_and_Materials/pha10f19.svg"),
  caption: [
    #ez_caption[
      Finding the $r^2$ Ellipse Value for the EWA Filter Table Lookup.
    ][

    ]
  ],
)<ewa-ellipse-eval>

#parec[
  Now that the bounding box is known, the EWA algorithm loops over the texels, transforming each one to the coordinate system where the texture lookup point $(s , t)$ is at the origin with a translation. It then evaluates the ellipse equation to see if the texel is inside the ellipse (@fig:ewa-ellipse-eval) and computes the filter weight for the texel if so. The final filtered value returned is a weighted sum over texels $T (s prime , t prime)$ inside the ellipse, where $f$ is the Gaussian filter function:
][
  现在已知边界框，EWA 算法遍历 texel，将每个 texel 转换到坐标系中，其中纹理查找点 $(s , t)$ 通过平移位于原点。 然后评估椭圆方程以查看 texel 是否在椭圆内（@fig:ewa-ellipse-eval），如果是，则计算 texel 的滤波权重。返回的最终滤波值是椭圆内 texel $T (s prime , t prime)$ 的加权和，其中 $f$ 是高斯滤波函数：
]

$ frac(sum f (s prime - s , t prime - t) T (s prime , t prime), sum f (s prime - s , t prime - t)) $

```cpp
T sum{};
Float sumWts = 0;
for (int it = t0; it <= t1; ++it) {
    Float tt = it - st[1];
    for (int is = s0; is <= s1; ++is) {
        Float ss = is - st[0];
        // Compute squared radius and filter texel if it is inside the ellipse
        Float r2 = A * Sqr(ss) + B * ss * tt + C * Sqr(tt);
        if (r2 < 1) {
            int index = std::min<int>(r2 * MIPFilterLUTSize, MIPFilterLUTSize - 1);
            Float weight = MIPFilterLUT[index];
            sum += weight * Texel<T>(level, {is, it});
            sumWts += weight;
        }
    }
}
return sum / sumWts;
```


#parec[
  A nice feature of the implicit equation $e (s , t)$ is that its value at a particular texel is the squared ratio of the distance from the center of the ellipse to the texel to the distance from the center of the ellipse to the ellipse boundary along the line through that texel (@fig:ewa-ellipse-eval). This value can be used to index into a precomputed lookup table of Gaussian filter function values.
][
  隐式方程 $e (s , t)$ 的一个不错的特性是，它在特定 texel 处的值是从椭圆中心到 texel 的距离与从椭圆中心到通过该 texel 的椭圆边界的距离的平方比（@fig:ewa-ellipse-eval）。此值可用于索引到预先计算的查找表中。
]

```cpp
Float r2 = A * Sqr(ss) + B * ss * tt + C * Sqr(tt);
if (r2 < 1) {
    int index = std::min<int>(r2 * MIPFilterLUTSize, MIPFilterLUTSize - 1);
    Float weight = MIPFilterLUT[index];
    sum += weight * Texel<T>(level, {is, it});
    sumWts += weight;
}
```

#parec[
  The lookup table is precomputed and available as a constant array. Similar to the Gaussian filter used for image reconstruction, the filter function is offset so that it goes to zero at the end of its extent rather than having an abrupt step. It is:
][
  查找表是预先计算的，并作为常量数组提供。类似于用于图像重建的高斯滤波器，滤波函数被调整，使其在范围末端变为零，而不是具有突然的步骤。 它是：
]

$ e^(- alpha r^2) - e^(- alpha) . $


#parec[
  $alpha = 2$ was used for the table in `pbrt`. Because the table is indexed with squared distances from the filter center $r^2$, each entry stores a value $e^(- alpha r)$, rather than $e^(- alpha r^2)$.
][
  在 `pbrt` 中表使用 $alpha = 2$。由于表是用从滤波器中心的距离平方 $r^2$ 索引的，因此每个条目存储一个值 $e^(- alpha r)$，而不是 $e^(- alpha r^2)$。
]

```cpp
static constexpr int MIPFilterLUTSize = 128;
static PBRT_CONST Float MIPFilterLUT[MIPFilterLUTSize] = {
    // MIPMap EWA Lookup Table Values
    0.864664733f,  0.849040031f,   0.83365953f,   0.818519294f,
    0.80361563f,   0.788944781f,   0.774503231f,  0.760287285f,
    0.746293485f,  0.732518315f,   0.718958378f,  0.705610275f,
    0.692470789f,  0.679536581f,   0.666804492f,  0.654271305f,
    0.641933978f,  0.629789352f,   0.617834508f,  0.606066525f,
    0.594482362f,  0.583079159f,   0.571854174f,  0.560804546f,
    0.549927592f,  0.539220572f,   0.528680861f,  0.518305838f,
    0.50809288f,   0.498039544f,   0.488143265f,  0.478401601f,
    0.468812168f,  0.45937258f,    0.450080454f,  0.440933526f,
    0.431929469f,  0.423066139f,   0.414341331f,  0.405752778f,
    0.397298455f,  0.388976216f,   0.380784035f,  0.372719884f,
    0.364781618f,  0.356967449f,   0.34927541f,   0.341703475f,
    0.334249914f,  0.32691282f,    0.319690347f,  0.312580705f,
    0.305582166f,  0.298692942f,   0.291911423f,  0.285235822f,
    0.278664529f,  0.272195935f,   0.265828371f,  0.259560347f,
    0.253390193f,  0.247316495f,   0.241337672f,  0.235452279f,
    0.229658857f,  0.223955944f,   0.21834214f,   0.212816045f,
    0.207376286f,  0.202021524f,   0.196750447f,  0.191561714f,
    0.186454013f,  0.181426153f,   0.176476851f,  0.171604887f,
    0.166809067f,  0.162088141f,   0.157441005f,  0.152866468f,
    0.148363426f,  0.143930718f,   0.139567271f,  0.135272011f,
    0.131043866f,  0.126881793f,   0.122784719f,  0.11875169f,
    0.114781633f,  0.11087364f,    0.107026696f,  0.103239879f,
    0.0995122194f, 0.0958427936f,  0.0922307223f, 0.0886750817f,
    0.0851749927f, 0.0817295909f,  0.0783380121f, 0.0749994367f,
    0.0717130303f, 0.0684779733f,  0.0652934611f, 0.0621587038f,
    0.0590728968f, 0.0560353249f,  0.0530452281f, 0.0501018465f,
    0.0472044498f, 0.0443523228f,  0.0415447652f, 0.0387810767f,
    0.0360605568f, 0.0333825648f,  0.0307464004f, 0.0281514227f,
    0.0255970061f, 0.0230824798f,  0.0206072628f, 0.0181707144f,
    0.0157722086f, 0.013411209f,   0.0110870898f, 0.0087992847f,
    0.0065472275f, 0.00433036685f, 0.0021481365f, 0.f
};
```

